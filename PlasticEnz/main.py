#!/usr/bin/env python3import osimport sysimport argparseimport loggingfrom tqdm import tqdmfrom time import sleepdef display_logo():    """Display the PlasticEnz logo and citations."""    logo = """       ___ _           _   _        __                / _ | | __ _ ___| |_(_) ___  /___ __  ____     / /_)| |/ _` / __| __| |/ __|/_\| '_ \|_  /    / ___/| | (_| \__ | |_| | (__//__| | | |/ /     \/    |_|\__,_|___/\__|_|\___\__/|_| |_/___|                                                        #####################################    #        Welcome to PlasticEnz      #    #####################################        """    print(logo)    print("\nPlease remember to cite following tools:")    print("- Prodigal: Hyatt et al., 2010. BMC Bioinformatics. DOI: 10.1186/1471-2105-11-119")    print("- HMMER: Eddy, 2011. PLoS Comput Biol. DOI: 10.1371/journal.pcbi.1002195")    print("- DIAMOND: Buchfink et al., 2015. Nat Methods. DOI: 10.1038/nmeth.3176")    print("- Bowtie2: Langmead & Salzberg, 2012. Nat Methods. DOI: 10.1038/nmeth.1923")    print("- Samtools: Danecek et al., 2021. Gigascience. DOI: 10.1093/gigascience/giab008")    print("- ProtTrans: Elnaggar et al., 2022. IEEE TPAMI. DOI: 10.1109/TPAMI.2021.3095381")    print("\n")def simulated_loading_bar(task_name, duration=3):    """Simulate a loading bar for a task."""    print(f"\n{task_name} is starting. Please wait...")    for _ in tqdm(range(duration), desc=f"{task_name} in progress", unit="steps"):        sleep(1)    print(f"{task_name} completed.\n")def parse_args():    """Set up and return the argument parser."""    parser = argparse.ArgumentParser(        description="PlasticEnz: A tool for detecting plastic-degrading enzymes from sequence data.",        formatter_class=argparse.ArgumentDefaultsHelpFormatter,    )    # Input files    parser.add_argument("-c", "--contigs", type=str, help="Path to contigs file (FASTA).")    parser.add_argument("-1", "--reads_forward", type=str, help="Path to forward reads file (FASTQ).")    parser.add_argument("-2", "--reads_reverse", type=str, help="Path to reverse reads file (FASTQ).")    parser.add_argument("-p", "--proteins", type=str, help="Path to protein file (FASTA).")    parser.add_argument("-g", "--genome", type=str, help="Path to genome or MAG file (FASTA).")    # Polymer and output directory    parser.add_argument("--cores", type=int, default=1, help="Number of CPU cores to use.")    parser.add_argument("--polymer", type=str, default=None, help="Polymer(s) to screen for. Use 'all' for all available.")    parser.add_argument("--outdir", type=str, default=None, help="Output directory.")    # Performance and thresholds    parser.add_argument("--use_gpu", action="store_true", help="Attempt to use GPU for accelerated computations.")    parser.add_argument("--evalue_hmmer", type=float, default=1e-5, help="E-value threshold for HMMER search.")    parser.add_argument("--bitscore_hmmer", type=float, default=20, help="Bitscore value for HMMER search.")    parser.add_argument("--evalue_diamond", type=float, default=1e-5, help="E-value threshold for DIAMOND search.")    parser.add_argument("--bitscore_diamond", type=float, default=20, help="Minimum alignment quality for DIAMOND search.")    # Test mode    parser.add_argument("--test", action="store_true", help="Run the tool with a predefined test dataset.")    # New flag to select the sensitive model (neural network)    parser.add_argument("--sensitive", action="store_true", help="Use neural network model (nn_model.pkl) for sensitive predictions.")    return parserdef main():    parser = parse_args()    # Early check: if no arguments or --help/-h is present, show help and exit before loading heavy modules.    if len(sys.argv) == 1 or any(arg in sys.argv for arg in ("-h", "--help")):        display_logo()        parser.print_help()        sys.exit(0)    # Delay importing heavy modules until after we've checked for help.    import PlasticEnz    from PlasticEnz.modules.run_prodigal import run_prodigal    from PlasticEnz.modules.run_hmmer import run_hmmer    from PlasticEnz.modules.run_diamond import run_diamond    from PlasticEnz.modules.run_extract import run_extract    from PlasticEnz.modules.run_prediction import run_predictions    from PlasticEnz.modules.run_mapping import run_mapping    from PlasticEnz.modules.run_signalp import run_signalp    from PlasticEnz.modules.utility_functions import (        validate_inputs,        validate_polymers,        merge_abundance_with_summary,    )    # Define test data directory (inside the package)    TEST_DATA_DIR = os.path.join(os.path.dirname(PlasticEnz.__file__), "test")    display_logo()    args = parser.parse_args()    # Set test dataset paths if in test mode    if args.test:        if not args.outdir:            parser.error("‚ùå Error: When using --test mode, you must provide --outdir.")        print("üß™ Running PlasticEnz in test mode...")        args.genome = os.path.join(TEST_DATA_DIR, "Bacterioplankton_PLA.117.fa")        args.reads_forward = ",".join([            os.path.join(TEST_DATA_DIR, "S1_forward_1.fastq"),            os.path.join(TEST_DATA_DIR, "S2_forward_2.fastq"),            os.path.join(TEST_DATA_DIR, "S3_forward_3.fastq"),        ])        args.reads_reverse = ",".join([            os.path.join(TEST_DATA_DIR, "S1_reverse_1.fastq"),            os.path.join(TEST_DATA_DIR, "S2_reverse_2.fastq"),            os.path.join(TEST_DATA_DIR, "S3_reverse_3.fastq"),        ])        args.polymer = "PET,PLA"                try:            import shutil            if shutil.which("signalp6"):                args.signalp = True                args.signalp_mode = "fast"                args.signalp_organism = "auto"                args.signalp_batch_size = 8                if args.signalp_outdir is None:                    args.signalp_outdir = os.path.join(args.outdir, "signalp_test")                print("üß™ SignalP enabled for test run (fast, auto).")            else:                print("‚ÑπÔ∏è signalp6 not found in PATH; skipping SignalP in test.")        except Exception as _e:            print(f"‚ÑπÔ∏è Could not check SignalP availability: {_e}")    elif not args.polymer or not args.outdir:        parser.error("‚ùå Error: The --polymer and --outdir arguments are required unless using --test.")    # Validate inputs    validate_inputs(args)    valid_polymers = [poly.strip().upper() for poly in validate_polymers(args.polymer)]    # Create directories for outputs    os.makedirs(args.outdir, exist_ok=True)    final_output_dir = os.path.join(args.outdir, "output")    os.makedirs(final_output_dir, exist_ok=True)    # Configure logging    logger = logging.getLogger("PlasticEnz")    logger.setLevel(logging.INFO)    main_log_file = os.path.join(args.outdir, "main.log")    handler = logging.FileHandler(main_log_file)    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')    handler.setFormatter(formatter)    logger.addHandler(handler)    # Run Prodigal    if args.genome:        try:            print(f"üß™Running Prodigal on genome/MAG file: {args.genome}")            protein_out, gene_out, _ = run_prodigal(args.genome, args.outdir, cores=args.cores, is_genome=True)            protein_file = protein_out        except Exception as e:            logger.error(f"Error running Prodigal: {e}")            sys.exit(f"‚ùåERROR: Prodigal failed on genome/MAG file: {e}")    elif args.contigs:        try:            print(f"üß™Running Prodigal on contigs: {args.contigs}")            protein_out, gene_out, _ = run_prodigal(args.contigs, args.outdir, cores=args.cores, is_genome=False)            protein_file = protein_out        except Exception as e:            logger.error(f"Error running Prodigal: {e}")            sys.exit(f"‚ùåERROR: Prodigal failed on contigs file: {e}")    else:        protein_file = args.proteins    if protein_file is None:        sys.exit("‚ùåError: No valid protein file available for HMMER step.")    # For each polymer, run separate HMMER and DIAMOND searches    hmmer_outputs = []    diamond_outputs = []    for poly in valid_polymers:        print(f"üß™Running HMMER for polymer: {poly}")        try:            outs = run_hmmer(                proteins=protein_file,                polymer=poly,  # pass one polymer at a time                bitscore=args.bitscore_hmmer,                outdir=args.outdir,                evalue=args.evalue_hmmer,                cores=args.cores,            )            hmmer_outputs.extend(outs)        except Exception as e:            logger.error(f"Error running HMMER for {poly}: {e}")            sys.exit(f"‚ùåERROR: HMMER failed for {poly}: {e}")        print(f"üß™Running DIAMOND for polymer: {poly}")        try:            outs = run_diamond(                proteins=protein_file,                polymer=poly,  # pass one polymer at a time                outdir=args.outdir,                evalue=args.evalue_diamond,                min_score=args.bitscore_diamond,                cores=args.cores,            )            diamond_outputs.extend(outs)        except Exception as e:            logger.error(f"Error running DIAMOND for {poly}: {e}")            sys.exit(f"‚ùåERROR: DIAMOND failed for {poly}: {e}")    # Extract homologues and proteins    try:        summary_file, fasta_file = run_extract(            hmmer_outputs=hmmer_outputs,            diamond_outputs=diamond_outputs,            protein_file=protein_file,            output_dir=final_output_dir,        )    except Exception as e:        logger.error(f"Error during extraction: {e}")        sys.exit(f"‚ùåERROR: Extraction failed: {e}")            # Map reads and calculate abundances (if both forward and reverse reads are provided)    if args.reads_forward and args.reads_reverse:        try:            abundance_file = run_mapping(                forward_reads=args.reads_forward.split(","),                reverse_reads=args.reads_reverse.split(","),                genes_file=gene_out,                outdir=args.outdir,            )        except Exception as e:            logger.error(f"Error during reads mapping: {e}")            sys.exit(f"‚ùåERROR: Reads mapping failed: {e}")                # Merge abundances into summary            #try:                #merge_abundance_with_summary(summary_file, abundance_file)            #except Exception as e:                #logger.error(f"Error merging abundances: {e}")                #sys.exit(f"‚ùåERROR: Failed to merge abundances: {e}")        # Run prediction only for PET and/or PHB    prediction_polymers = [poly for poly in valid_polymers if poly in {"PET", "PHB"}]    if prediction_polymers:        try:            print("üß™Running prediction step...")            logger.info("Running prediction step.")            if args.sensitive:                model_path = os.path.join(os.path.dirname(__file__), "data", "model", "nn_model.pt")                model_tag = "nn"            else:                model_path = os.path.join(os.path.dirname(__file__), "data", "model", "xgb_model.pkl")                model_tag = "xgb"            # Pass prediction_polymers and also model_tag so that column names can include it.            run_predictions(                fasta_file=fasta_file,                summary_table=summary_file,                gpu=args.use_gpu,                model_path=model_path,                polymers=prediction_polymers,                model_tag=model_tag  # new parameter for naming            )        except Exception as e:            logger.error(f"Error during prediction: {e}")            sys.exit(f"‚ùåERROR: Prediction failed: {e}")    else:        print("‚ÑπÔ∏èSkipping prediction step (PET and PHB not provided).")    print("‚úÖPlasticEnz analysis completed successfully!")    logger.info("PlasticEnz analysis completed successfully.")if __name__ == "__main__":    main()